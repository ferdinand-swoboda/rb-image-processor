# rb-image-processor
The application is a batch image processor that takes a work image API URL and an output directory path, retrieves the image data and transforms it in a structured set of HTML pages that allows to browse the works' images by camera make and camera model. The set of HTML pages is written to the specified output directory.

The application is written in Java as a Gradle (dependency manager similar to Maven) project. Therefore, at least JDK 1.8 is required. 

## Development
As this is a Gradle project, it can be easily imported as such in the IDE of your choice, preferably IntelliJ IDEA.
The Gradle configuration supports multiple tasks and wraps a self-contained Gradle installation meaning a system installation of Gradle is not required. This means, you can run any Gradle task in your project using the gradlew shell script or bat file located in the root directory.
However a Gradle plugin for your IDE will be needed to execute the Gradle tasks from within the IDE.

From within the project's root directory, you can execute any Gradle task by running

 - `./gradlew <task>` (on Unix-like platforms such as Linux and Mac OS X)
 - `gradlew <task>` (on Windows using the gradlew.bat batch file)

where \<task\> is replaced with test/build/installDist/clean etc.
Arguments have to be changed accordingly, if necessary.

## Usage
After the project has been installed the project's root directory has a build/install/bin subfolder that contains ready-to-use start scripts for both Windows and Unix systems.
To execute the application on e.g. Windows run the following command in the aforementioned subfolder:

`rb-image-processor http://take-home-test.herokuapp.com/api/ C:\Users\<username>\Desktop\htmlPages`

## Architecture
At a high level, the task the application sets out to solve is a transformation, that is applied to data of a certain source type and generates data of a certain target type. The source data in this case is XML-encoded work image data and the target data is HTML text file data. 

Consequently, the processor is built after the idea of a pipeline that reads data from a data source, applies one (or multiple transformations) to it and writes the results to a data target.

You will find three packages datasource, data target and transformation in the code base that encapsulate these functionalities and are separated by generic interfaces so that it is easy to add other data sources or targets etc. A fourth package, domain, contains the internal data abstraction Work that represents a work image and its camera make, model etc.

Because the data source accesses its, as XML persisted, data remotely, the type-safe HTTP client Retrofit takes over all the heavy lifting of requesting the XML document and parsing it into our internal abstraction class.

The transformation part is the complicated one. It is split up in three parts:

 1. We first need to identify the work images that belong to the same camera make or the same camera make and model (model alone may not be unique). This is the foundation of the HTML page hierarchy we are about to generate.
 2. Because the HTML pages link to each other in their navigation bar, we have to collect the HTML page names under which the HTML pages will be available.
 3. The actual HTML page is created by merging the static template data with the dynamic data (i.e. the HTML page names we want to link to etc.). This is where the HTML page body is generated by the Thymeleaf template engine.

The set of HTML pages or, better, HTML texts as referred to in the code base is then written to the local file system by the data target. It uses the HTML text name as the file name of the HTML text body to be written in the output directory.

## Comments
Java, Gradle and the Retrofit as well as Thymeleaf library were chosen due to familiarity and because they need minimum configuration to solve the given task at hand. Both can easily replaced with alternatives.

Currently, the application performs all transformation steps strictly sequentially. Since it is intended as a batch processor handling a moderate amount of data and given that only the pure HTML generation could be parallelised this is considered to be acceptable. 

The application also writes the set of generated HTML pages directly in the output directory. Specifically, it does not create a subfolder structure reflecting the HTML page hierarchy with index.html at the top and a second layer of directories for each camera make.

Due to unavailability of Unix systems, the code has not been tested thoroughly on macOS etc. 

At last, have fun diving in the code!
